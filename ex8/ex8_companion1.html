<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,IE=9,chrome=1"><meta name="generator" content="MATLAB 2020b"><title>MATLAB Companion Script (1 of 2) for Machine Learning ex8 (Optional)</title><style type="text/css">.rtcContent { padding: 30px; } .S0 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 28.8px; min-height: 0px; white-space: pre-wrap; color: rgb(213, 80, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 24px; font-weight: 400; text-align: left;  }
.S1 { margin: 20px 10px 5px 4px; padding: 0px; line-height: 20px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 20px; font-weight: 700; text-align: left;  }
.S2 { margin: 2px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: left;  }
.S3 { margin: 10px 0px 20px; padding-left: 0px; font-family: Helvetica, Arial, sans-serif; font-size: 14px;  }
.S4 { margin-left: 56px; line-height: 21px; min-height: 0px; text-align: left; white-space: pre-wrap;  }
.S5 { margin-bottom: 20px; padding-bottom: 4px;  }
.S6 { margin: 0px; padding: 10px 0px 10px 5px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 700; text-align: start;  }
.S7 { margin: -1px 0px 0px; padding: 10px 0px 10px 7px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: start;  }
.CodeBlock { background-color: #F7F7F7; margin: 10px 0 10px 0;}
.S8 { border-left: 1px solid rgb(233, 233, 233); border-right: 1px solid rgb(233, 233, 233); border-top: 1px solid rgb(233, 233, 233); border-bottom: 0px none rgb(0, 0, 0); border-radius: 4px 4px 0px 0px; padding: 6px 45px 0px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S9 { border-left: 1px solid rgb(233, 233, 233); border-right: 1px solid rgb(233, 233, 233); border-top: 0px none rgb(0, 0, 0); border-bottom: 0px none rgb(0, 0, 0); border-radius: 0px; padding: 0px 45px 0px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S10 { border-left: 1px solid rgb(233, 233, 233); border-right: 1px solid rgb(233, 233, 233); border-top: 0px none rgb(0, 0, 0); border-bottom: 1px solid rgb(233, 233, 233); border-radius: 0px 0px 4px 4px; padding: 0px 45px 4px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S11 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 20px; min-height: 0px; white-space: pre-wrap; color: rgb(60, 60, 60); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 20px; font-weight: 700; text-align: left;  }
.S12 { margin: 10px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: left;  }
.S13 { border-left: 1px solid rgb(233, 233, 233); border-right: 1px solid rgb(233, 233, 233); border-top: 1px solid rgb(233, 233, 233); border-bottom: 1px solid rgb(233, 233, 233); border-radius: 4px; padding: 6px 45px 4px 13px; line-height: 17.234px; min-height: 18px; white-space: nowrap; color: rgb(0, 0, 0); font-family: Menlo, Monaco, Consolas, "Courier New", monospace; font-size: 14px;  }
.S14 { margin: 2px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(0, 0, 0); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: center;  }</style></head><body><div class = rtcContent><h1  class = 'S0' id = 'T_13370202' ><span>MATLAB Companion Script (1 of 2) for </span><span style=' font-style: italic;'>Machine Learning</span><span> ex8 (Optional)</span></h1><h2  class = 'S1' id = 'H_5E50F655' ><span>Introduction</span></h2><div  class = 'S2'><span>Coursera's</span><span style=' font-style: italic;'> Machine Learning</span><span> was designed to provide you with a greater understanding of machine learning algorithms- what they are, how they work, and where to apply them. You are also shown techniques to improve their performance and to address common issues. As is mentioned in the course, there are many tools available that allow you to use machine learning algorithms </span><span style=' font-style: italic;'>without</span><span> having to implement them yourself. This Live Script was created by MathWorks to help </span><span style=' font-style: italic;'>Machine Learning</span><span> students explore the data analysis and machine learning tools available in MATLAB.</span></div><h2  class = 'S1' id = 'H_8D135D31' ><span>FAQ</span></h2><div  class = 'S2'><span style=' font-weight: bold;'>Who is this intended for?</span></div><ul  class = 'S3'><li  class = 'S4'><span>This script is intended for students using MATLAB Online who have completed ex8 and want to learn more about the corresponding machine learning tools in MATLAB.</span></li></ul><div  class = 'S2'><span style=' font-weight: bold;'>How do I use this script?</span></div><ul  class = 'S3'><li  class = 'S4'><span>In the sections that follow, read the information provided about the data analysis and machine learning tools in MATLAB, then run the code in each section and examine the results. You may also be presented with instructions for using a MATLAB machine learning app. This script should be located in the ex8 folder which should be set as your Current Folder in MATLAB Online.</span></li></ul><div  class = 'S2'><span style=' font-weight: bold;'>Can I use the tools in this companion script to complete the programming exercises?</span></div><ul  class = 'S3'><li  class = 'S4'><span>No. Most algorithm steps implemented in the programming exercises are handled automatically by MATLAB machine learning functions. Additionally, the results will be similar, but not identical, to those in the programming exercises due to differences in implementation, parameter settings, and randomization.</span></li></ul><div  class = 'S2'><span style=' font-weight: bold;'>Where can I obtain help with this script or report issues?</span></div><ul  class = 'S3'><li  class = 'S4'><span> As this script is not part of the original course materials, please direct any questions, comments, or issues to the </span><span style=' font-style: italic;'>MATLAB Help</span><span> discussion forum.</span></li></ul><h1  class = 'S0' id = 'T_AFA02A62' ><span>Anomaly Detection</span></h1><div  class = 'S2'><span>In the first part of this Live Script, we will use tools from the </span><a href = "https://www.mathworks.com/products/statistics.html"><span>Statistics and Machine Learning Toolbox</span></a><span> to implement an anomaly detection system. We then discuss methods for fitting statistical distributions to measured data, as well as adjusting and evaluating the performance of our detector. </span></div><h2  class = 'S1' id = 'H_C2BB7182' ><span>Files needed for this script</span></h2><ul  class = 'S3'><li  class = 'S4'><span style=' font-family: monospace;'>ex8data1.mat</span><span> - First example dataset for anomaly detection</span></li><li  class = 'S4'><span style=' font-family: monospace;'>ex8data2.mat</span><span> - Second example dataset for anomaly detection</span></li></ul><div  class = 'S5'><div  class = 'S6'><span style=' font-weight: bold;'>Table of Contents</span></div><div  class = 'S7'><a href = "#T_13370202"><span>MATLAB Companion Script (1 of 2) for Machine Learning ex8 (Optional)
</span></a><span>    </span><a href = "#H_5E50F655"><span>Introduction
</span></a><span>    </span><a href = "#H_8D135D31"><span>FAQ
</span></a><a href = "#T_AFA02A62"><span>Anomaly Detection
</span></a><span>    </span><a href = "#H_C2BB7182"><span>Files needed for this script
</span></a><a href = "#T_58724955"><span>Data Visualization and Probability Distribution Fitting
</span></a><span>    </span><a href = "#H_9AD2B953"><span>Load the data
</span></a><span>    </span><a href = "#H_9F3759A7"><span>Visualize the data using scatterhist 
</span></a><span>    </span><a href = "#H_8F07B856"><span>Visualize distribution fits using histfit
</span></a><span>    </span><a href = "#H_0918A10E"><span>Fit a probability distribution to data using fitdist
</span></a><span>    </span><a href = "#H_14F259BD"><span>Fit a probability distribution to data using the Distribution Fitter App
</span></a><span>    </span><a href = "#H_30595E5C"><span>Fit a normal distribution and export the NormalDistribution variable to the workspace
</span></a><span>    </span><a href = "#H_639E8403"><span>Evaluate the fit and extract the parameters
</span></a><span>    </span><a href = "#H_CE35F154"><span>Obtain the multivariate normal PDF values using mvnpdf 
</span></a><a href = "#T_697FF7EA"><span>Model Assessment and Cutoff Parameter Selection
</span></a><span>    </span><a href = "#H_DB40C945"><span>Obtain the confusion matrix and calculate the  score
</span></a><span>    </span><a href = "#H_E4CD52C0"><span>Determine the optimal cuttoff value using performance curves
</span></a><span>    </span><a href = "#H_B8C43CFF"><span>Compare model performance using ROC curves
</span></a><span>    </span><a href = "#H_76E52164"><span>Fit a multivariate probability model to the high dimensional dataset
</span></a><a href = "#T_F877B50F"><span>Local Functions
</span></a><span>    </span><a href = "#H_10E7FDFA"><span>probContour</span></a></div></div><h1  class = 'S0' id = 'T_58724955' ><span>Data Visualization and Probability Distribution Fitting</span></h1><div  class = 'S2'><span>In this section we visualize the sever data from ex8 using scatter plots and histograms before fitting a distribution to the data using functions and apps from the Statistics and Machine Learning Toolbox. </span></div><h2  class = 'S1' id = 'H_9AD2B953' ><span>Load the data</span></h2><div  class = 'S2'><span>Recall that the data used in the first part of ex8 consisted of two features: measurements of the throughput (mb/s) and latency (ms) each server as well as a separate set validation measurements and labels that denoted anomalous behavior. Run the code in this section to load the variables </span><span style=' font-family: monospace;'>X</span><span>, </span><span style=' font-family: monospace;'>Xval</span><span> and </span><span style=' font-family: monospace;'>yval</span><span> into the workspace and create a </span><span style=' font-family: monospace;'>table</span><span> for the validation data and labels, then compute some summary statistics on the validation data. Recall that 0's denote normal behavior and 1's denote anomalous behavior.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>clear;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>load(</span><span style="color: rgb(170, 4, 249);">'ex8data1.mat'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>dataval = table(Xval(:,1),Xval(:,2),yval==1,</span><span style="color: rgb(170, 4, 249);">'VariableNames'</span><span>,{</span><span style="color: rgb(170, 4, 249);">'Throughput'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Latency'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Anomaly'</span><span>});</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>summary(dataval)</span></span></div></div></div><h2  class = 'S11' id = 'H_9F3759A7' ><span>Visualize the data using </span><span style=' font-family: monospace;'>scatterhist</span><span> </span></h2><div  class = 'S2'><span>Before fitting a distribution to data, it's helpful to visualize the data to see what existing probability distributions might make for a reasonable fit. Run the code below to see how the values of the normal and anomalous data is distributed across the two variable values using the </span><a href = "https://www.mathworks.com/help/stats/scatterhist.html"><span style=' font-family: monospace;'>scatterhist</span></a><span> function.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>scatterhist(dataval.Throughput,dataval.Latency,</span><span style="color: rgb(170, 4, 249);">'Group'</span><span>,dataval.Anomaly,</span><span style="color: rgb(170, 4, 249);">'Kernel'</span><span>,</span><span style="color: rgb(170, 4, 249);">'on'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Marker'</span><span>,</span><span style="color: rgb(170, 4, 249);">'x'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Throughput'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'Latency'</span><span>);</span></span></div></div></div><div  class = 'S12'><span>From the resulting plot, the 'normal behavior' observations appears approximately normally distributed with most observations concentrated symmetricaly about the mean. The 'anomalous behavior' observations appear more evenly distributed over the range of variable values and also appear symmetrically distributed about the overall means, however there are considerably fewer anomalous observations.</span></div><h2  class = 'S11' id = 'H_8F07B856' ><span>Visualize distribution fits using </span><span style=' font-family: monospace;'>histfit</span></h2><div  class = 'S2'><span>Below we provide code to visualize potential distribution fits using the </span><a href = "https://www.mathworks.com/help/stats/histfit.html"><span style=' font-family: monospace;'>histfit</span></a><span> function, which plots a histogram of the data and the fitted distribution. Run the code to plot two potential distribution fits for each variable, the normal and t-distributions, for comparison.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>f = figure;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>subplot(2,2,1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>histfit(dataval.Throughput,25,</span><span style="color: rgb(170, 4, 249);">'normal'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'Normal distribution fit'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Throughput'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>axis </span><span style="color: rgb(170, 4, 249);">square</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>subplot(2,2,2); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>histfit(dataval.Throughput,25,</span><span style="color: rgb(170, 4, 249);">'tlocationscale'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'t-distribution fit'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Throughput'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>subplot(2,2,3);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>histfit(dataval.Latency,25,</span><span style="color: rgb(170, 4, 249);">'normal'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'Normal distribution fit'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Latency'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>axis </span><span style="color: rgb(170, 4, 249);">square</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>subplot(2,2,4); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>histfit(dataval.Latency,25,</span><span style="color: rgb(170, 4, 249);">'tlocationscale'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'t-distribution fit'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'Latency'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>set([f.Children.YLabel],</span><span style="color: rgb(170, 4, 249);">'String'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Count'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>axis </span><span style="color: rgb(170, 4, 249);">square</span></span></div></div></div><div  class = 'S12'><span>While the t-distribution appears to offer better fit to the data based on the above plots, the normal distribution is still a reasonable choice and offers easier comparison with the results from ex8, so we will use that distribution in the next few sections. </span></div><h2  class = 'S11' id = 'H_0918A10E' ><span>Fit a probability distribution to data using </span><span style=' font-family: monospace;'>fitdist</span></h2><div  class = 'S2'><span>To fit a distribution to each variable, we will use the </span><a href = "https://www.mathworks.com/help/stats/fitdist.html"><span style=' font-family: monospace;'>fitdist</span></a><span> function, which takes a data vector and distribution name as input, and returns the fitted distribution parameters as output. The number and meaning of the parameters vary by distribution- see the </span><a href = "https://www.mathworks.com/help/stats/fitdist.html#btu538h-distname"><span>documentation</span></a><span> for more details and available distributions. Run the code below to fit a normal distribution to the Throughput data (we fit a normal distribution to the Latency data in the next section). The </span><span style=' font-family: monospace;'>fitdist</span><span> function will return a </span><span style=' font-family: monospace;'>NormalDistribution</span><span> variable that contains the parameters as well as additional fit information including the confidence bounds for each parameter. We then extract the parameters into the first elements of the variables </span><span style=' font-family: monospace;'>mu</span><span> and </span><span style=' font-family: monospace;'>sigma</span><span> respectively. </span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>mu = zeros(1,2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>sigma = mu;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>distMdl1 = fitdist(dataval.Throughput,</span><span style="color: rgb(170, 4, 249);">'Normal'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>mu(1) = distMdl1.mu;</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>sigma(1) = distMdl1.sigma;</span></span></div></div></div><div  class = 'S2' id = 'H_5632C2D3' ><span style=' font-weight: bold;'>Note: </span><span>If you have difficulty reading the instructions below while the app is open in MATLAB Online, export this script to a pdf file which you can then use to display the instructions in a separate browser tab or window. To export this script, click on the 'Save' button in the 'Live Editor' tab above, then select 'Export to PDF'.</span></div><h2  class = 'S1' id = 'H_14F259BD' ><span>Fit a probability distribution to data using the Distribution Fitter App</span></h2><div  class = 'S2'><span>In the next few sections we provide instructions for fitting a normal distribution to the latency data using the</span><a href = "https://www.mathworks.com/help/stats/model-data-using-the-distribution-fitting-tool.html"><span> Distribution Fitter App</span></a><span> and export/extract the model parameters:</span></div><ol  class = 'S3'><li  class = 'S4'><span>In the '</span><span style=' font-weight: bold;'>Apps</span><span>' tab,  expand the list of apps and select '</span><span style=' font-weight: bold;'>Distribution Fitter</span><span>' from the '</span><span style=' font-weight: bold;'>Math, Statistics, and Optimization</span><span>' group.</span></li><li  class = 'S4'><span>Click on the '</span><span style=' font-weight: bold;'>Data</span><span>' button.</span></li><li  class = 'S4'><span>Expand the '</span><span style=' font-weight: bold;'>Data</span><span>' drop-down menu under '</span><span style=' font-weight: bold;'>Import workspace vectors'</span><span> and select '</span><span style=' font-weight: bold;'>Xval</span><span>'.</span></li><li  class = 'S4'><span>Click on the '</span><span style=' font-weight: bold;'>Select Column or Row</span><span>' button. In the box that appears, click on the '</span><span style=' font-weight: bold;'>2</span><span>' at the top of the second column to select the entire column, then click '</span><span style=' font-weight: bold;'>OK</span><span>'.</span></li><li  class = 'S4'><span>Click on the '</span><span style=' font-weight: bold;'>Create Data Set</span><span>' button, then click '</span><span style=' font-weight: bold;'>Close</span><span>'.</span></li></ol><h2  class = 'S11' id = 'H_30595E5C' ><span>Fit a normal distribution and export the </span><span style=' font-family: monospace;'>NormalDistribution</span><span> variable to the workspace</span></h2><ol  class = 'S3'><li  class = 'S4'><span>In the Distribution Fitter window, click on the '</span><span style=' font-weight: bold;'>'New Fit</span><span>' button</span></li><li  class = 'S4'><span>In the '</span><span style=' font-weight: bold;'>New Fit</span><span>' window, confirm that the second column of </span><span style=' font-family: monospace;'>Xval</span><span> is selected in '</span><span style=' font-weight: bold;'>Data</span><span>', and '</span><span style=' font-weight: bold;'>Normal</span><span>' is selected in </span><span style=' font-weight: bold;'>'Distribution</span><span>'.</span></li><li  class = 'S4'><span>Click the '</span><span style=' font-weight: bold;'>Apply</span><span>' button.</span></li><li  class = 'S4'><span>Click on the '</span><span style=' font-weight: bold;'>Save to Workspace</span><span>' button. </span></li><li  class = 'S4'><span>In the '</span><span style=' font-weight: bold;'>Save fitted distribution as:</span><span>' box that appears, enter '</span><span style=' font-weight: bold;'>distMdl2</span><span>' then click '</span><span style=' font-weight: bold;'>Ok</span><span>'</span></li><li  class = 'S4'><span>Close the '</span><span style=' font-weight: bold;'>Edit</span><span> </span><span style=' font-weight: bold;'>Fit</span><span>' menu (the 'New Fit' menu becomes the 'Edit Fit' menu once a distribution is fitted).</span></li></ol><h2  class = 'S11' id = 'H_639E8403' ><span>Evaluate the fit and extract the parameters</span></h2><ol  class = 'S3'><li  class = 'S4'><span>In the plot shown, compare the fitted PDF with the histogram. </span></li><li  class = 'S4'><span>The default plot view is 'Density Plot'. To further examine the fit, select one of the additional plot views in the '</span><span style=' font-weight: bold;'>Display Type</span><span>' drop-down menu.</span></li><li  class = 'S4'><span>When you are finished, close the Distribution Fitter App (there is no need to save the current session).</span></li><li  class = 'S4'><span>Run the code below to extract the values of </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">μ</span><span> and </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">σ</span><span> from the exported distribution variable into the second elements of the </span><span style=' font-family: monospace;'>mu</span><span> and </span><span style=' font-family: monospace;'>sigma</span><span> vectors created earlier.</span></li></ol><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>mu(2) = distMdl2.mu;</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>sigma(2) = distMdl2.sigma;</span></span></div></div></div><h2  class = 'S11' id = 'H_CE35F154' ><span>Obtain the multivariate normal PDF values using </span><span style=' font-family: monospace;'>mvnpdf</span><span> </span></h2><div  class = 'S2'><span>Now that we have fitted the probability distribution model coefficients, we'll create a contour plot of the probability distribution as in ex8. Run the code below to plot the observations and probability contours using the local function </span><span style=' font-family: monospace;'>probContour</span><span> defined at the end of this script. This function uses the </span><a href = "https://www.mathworks.com/help/stats/mvnpdf.html"><span style=' font-family: monospace;'>mvnpdf</span></a><span> function and the normal distribution parameters fitted previously to calculate the multivariate probability values for a grid of throughput and latency values.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S13'><span style="white-space: pre;"><span>probContour(dataval,mu,sigma);</span></span></div></div></div><h1  class = 'S0' id = 'T_697FF7EA' ><span>Model Assessment and Cutoff Parameter Selection</span></h1><div  class = 'S2' id = 'T_342876FA' ><span>After obtaining the distribution parameters, the next step in implementing the anomaly detection model is to select a cutoff parameter for flagging anomalies using the labeled validation data. In this section we use tools including the confusion matrix and performance curves for visualizing and evaluating model performance for various choices of this parameter, then we provide a method for obtaining this value automatically using the </span><span style=' font-family: monospace;'>perfcurve</span><span> function.</span></div><h2  class = 'S1' id = 'H_DB40C945' ><span>Obtain the confusion matrix and calculate the </span><span texencoding="F_1" style="vertical-align:-9px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADcAAAA+CAYAAACP1IOOAAAFCklEQVRoQ+1aTWgkRRR+r7snyYSsyqJZExT2xwj+oMjoDjNd3bSKYERhFV1kwT24op7U9bLqZdfbuuD/yT88KIhGXMSDEFCH6VcOxJOHzUVdRVbELObgKEjS3U8qzITZzvzUdM9oG6ZOSff7+b73VVe9qgRhGw/cxtxgRO7/qu5IuZFyGazAaFpmUBQtSCPltMqUQaORchkURQtSX8o5jvMgM7+qFTmZ0Z9EtC+Z61avvsjZtn0dIt4PAFcDwD0AsGNQQFQcRPzG9/39g4rZF7nWpKVSaadpmj91IFhh5tcB4LxpmmEYhoZpmmNhGE4h4sXMvBsRbwKAe2NEXiOiJ/9zcgqAEOI3AJiOgVkJw/CaWq222gtkuVzeZxhGBQCuaCj3kO/77/fy032fWDnbtncg4h9tEr1ARM/oArBtWyCir+yZ+Xop5Rld3152acjdrL6ReALDMG6vVqtf9krcfO953qVBEJxXv1uWlatUKoGuby+7xOQcxznKzC/FE1iWla9UKn/3StxCzgqCYB0AKkR0q66fjl1ickKIRQC4ozUJM38qpTygk7hpUy6Xpw3DUN/uSSJ6th/fXraJyHmeNxUEQT0enJkfl1K+0Stp/L3neZZ6NsgpubFA9QtE2Qsh7gSAz+O+YRjO1Wq17zvFdBxnfxRF41LKjQVk2CMpuRcB4OkYuLPduotisXhRLpc7p/a+QXYh3QqUlNwPALA39r29LKWME940EUKcAIDjAHCKiI4NW7VE09J13T1RFJ1t873dJaXcMlUb0/gBAPhI/WwYhl2tVr/OJDnbto8g4ttxcJOTk1OLi4t/NZ4bxWLxsrGxsauY+SAAPNF4vjIzMzO7sLAQZpKcEEIpoJSIjxUAyHdrplW/KaVsEh06v76+uUKhkMvn82tJUTHzbVLKr5L69+vXFznHcWxmpjZJHkZE1Sgr5dSelWfmWQA41DgeKZe6ZVk7B72XDWy1FEKo1U6teq1jhYguV31vPFGjuf6lMVXfJKLH+q2+sm90MWolPkZE2oJoG6okjuMsMfMtMYDvENEjnUALIdQ09Ji542rayVc11evr60cR8bmmDREZ7QrZLoY2uZYeMB7nIBEtdCGnjjDX9tNQe553SRAETzX2xQtCD4WcEGJzr2rNhojTvu9vHFniY35+frxer6sTwntEdFh3SgohbgSAA4h4mpnVSeGVFuW0BdE2FEKove1IjFjXO49SqZQ3TfMkM3+ctJ9snNY3+9VhKGcIIX5tc6Vwgoie11UkiZ1t27OIqBaljTHwBcVxnBuY+ds4OGZ2pJTttoYkPNr6DJ2cEEItw+okcMFYXV0dX15eTryp61Tg3yC35dQNAKeJ6D4dgGlshkqu06kbER/1ff+tNMB1fIdKTgihLk4/iQMxDGNvtVr9UQdgGpthk1PE4jfDquXalQa0ru/QyAkh7gaAz9oAqa+tre1ZWlr6XRdkUruBkisUCpMTExOHEdFpdPWdcK0w84cAcCaKoi+6XQwlJab8BkrO87zdQRD0+y0dIqIP0pDo5DtQcsMAmCbmiFyH6mk3zmmqn8Z3Wyvnuu6VURT93CzQwBvnNJVP6+u6bjmKItmME7tC7Bo+09PSdd25KIreVTtCkwUiHjdN85TOn8kySa5YLO7K5XLf9fiHgnOWZc11I5lJcmmn8qbKgwqUxTgj5bKoig6mkXI6VcqizUi5LKqig2mknE6VsmjzDx8p2U7F+9UqAAAAAElFTkSuQmCC" width="27.5" height="31" /></span><span> score</span></h2><div  class = 'S2'><span>In ex8 you used the validation set to select a probability cutoff parameter </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">ϵ</span><span> for anomaly prediction corresponding to the best </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> score. Recall that the </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> score depends on the </span><span style=' font-style: italic;'>precision</span><span> and </span><span style=' font-style: italic;'>recall</span><span> values, which in turn depend on the true positive, false positive, and false negative counts denoted </span><span texencoding="t_p" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABoAAAAoCAYAAADg+OpoAAACL0lEQVRYR+3WSajNYRjH8c8lQzLERtgpkTKvDCs2hBTKEDJEITuSIZEhGxspQ0QSUlJIKcMCJUqxUCwsZErKVMYMPbf33M49zvl3zv/ec7M47+p0zvM+3/P83t/7PG+TDlpNHcTRAOVWuiFdQ7oWBf47MyzDJ5zPe0jVVLQUx7EAZ+sFmo8zKfkAvGlv0DCsx4qU+DPG4yue5YGVk24mLmYk64zftcLKgXqiNxZjb0o4B3fxB69rhUR8lhlOJljE9Uiy5WE076kE6oQP6IWrmJqbkDZWAo3AoxQTpthXL9BaHEjJx+FBvUDhunBf2LovftUD1AU/UuJzmNdWSCUzTMCdlHwljtYLtBm7U/Ih+IIjmJEBDBV+pt+7FimSOSauYzJeIFrRTRzGsRLQKizC6NQP72ENxuI0NuBVYU+pveP+FA7+bbpL4biFqSuUFrUFu5IrL+EUNmE5thYp88+FDdD99K8iaZhhCb5XkK3QPWJOzU0x03AFNzClUkXxfX+MwXM8zjiX4u7RJw3GCC+MlkNYnQWq1mQj8RAnEBO4sPYUyRcDs3lVM2ErgddhP2bjQgqK3vgyfR6Md+0Buozp6If3KWEYYGe5sZ+3om74hqcYmiDxpghbt3JbWyuahFtFVYzCQGzHtXJa561oG3ZgFp6kR8vHLBflBd3GxJLzyXRrHtCg1J5iMIZkVa1aQcNTg41qYlZtxMFqSLWCuqcXUiF3PLta7ko9zqiaIlrF/AXdRWQpHRwrIQAAAABJRU5ErkJggg==" width="13" height="20" /></span><span>, </span><span texencoding="f_p" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABoAAAAoCAYAAADg+OpoAAACxklEQVRYR+3WT6hWZRAG8J+hKYmWhilJC91ILVKUUDRXShEtBFNKMLCColAXgogolpq2aCEoWLSoCDUJJMGQSlHwT4sQQTdRIG5MVCxLRUItZS5zLsfr+c53vnuvbuxdfX9m5pmZ93mfmQHu0xlwn3D8D9TrTj/YrRuEaXgBI/EjfsA/TfrZtHWPZeDn8BFexXi8j3X9BTQEB7Oa17ENhzATJzGxv4DexVYcx5QMGu1bgY/xfX8APYLTeALv4LMmQats2t3Ra/g6Hcfi7L0C2o05OIOnegsSflUVPY2HECQ4lsGPZuvi6zn80SloT6DHcbFNkLinuK+OTk+ggXnxESTex1sZbTZ+yc9XcbkjlBatK2IcwYz8Eqpws9PgZftWrIvA19NwX8pOX3BaDr5ncSIjN5aZukxaVfQGPk/HF1Pn7klFITkhPXGCiX/2CaWGDNG2aN9vmNBXkFYPdiiCwnF69WaqEqu6o+kIJYgTd/Vlg4qCpTfS7uESY7tdq4AWY0taPFN6qD3x3sZCTErh/RnvYTJ2YHlZhKuAvkIMuAsYg1s1Fa3Chzmr9uRQXIk3sRobCt8qoFM5pqOqpW3aViS1C/PS9iXsxQHMagU0OtU5/g+HuukZCv8XhuHRkv4VM+zT0hO5Sxnm4xtcybZdq6moUI8gS5CmOBtRtO+LckUjcCl/iD8WYRk2tWnbEmzGXHybtlHd7/k5tqTukRN3FGyZilE4nyQYh7pqItZ3eDl3vCLRIMB6LMDOcqIBFKyKabodr+QaFSOi7gzOxbGsHBE8aH0H28qtK+gb61S046cGD/R5HE67CBy73ZP4APur/KOiMPg329YAo8tkDdbm4vJrMvXvOud261Yr32L6xg5e3E9tkr0Biv0u1q/G63Bk0ClQaF8oeuwS8dZiLf6kSb87BQp2Di8F/q/BetZl3ilQk+QrbW4DaYN9KdevoQEAAAAASUVORK5CYII=" width="13" height="20" /></span><span>, and </span><span texencoding="f_n" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAoCAYAAADkDTpVAAACiklEQVRYR+3WS+jNCRQH8M9fyCMxwyBSKOOxQMljyEKNkZXymLFRZCHlUSispmyQwlAWFNLIY8PSq0gok9RIiZKNxOSV9zM6Olf//3Xv/d3//bMaZ/X73XvO9/zO9zybfGNp+sb4vjsoZPj/RVEHTMBv+BEncByvavFUL0U9EnAs1uMPDMafWNdWB51wOr9+Hv7GWUzGFYxqq4PF2IHLGJNgQdNqbMKxtjjoglvojUXYWViXZQpFOZiLA2nTH3e+toOjmIHbGNBa8NCvFMFwtEMk91KCnk+K4vUuHtTrrNxBT9wvMI48RD7qknIH7TOhYRz1vTBRfsW1fH6GJ3WhV6GoZHsOk/IluvhdvaDN9apVUQC+ScWTOR4awa+6cEbi30QsHAeNNNoC7E7DaTmHvmoEMRpiRIREZT1sCL1GkoOeoOkGhjYKXq3RuiJKMaRVNV/pQypV0URE54ZELvbWiCD6plS+8fweH4rKdAm2p9KIZg1WsluRu+EX7MJf2Ir5SelovCwpV4pgH2Kx/Ie+5V+EIQidWJ9TcqvFAorJ+zOG4XotBzdzHUYUy6rQEwCxRs/gII6g1PkxJF9Xc9Anp2X8P73KthqYSyh0NmINYjE9xxddX07RHBzG06TnRYUImjdhR7xFDMMAX4nN5Un+AY/yxz2ZrEjklir0HMLvmJnUhNqG3NFxAMQh8Fkign8wHj/hXiZ3ECp9fZRidHVUSazQUolGY4ZN3EuzMy+fnISDqNtIzH7MynMkElZJxuEitmF5KnTH46Toal4fcdq0cBAvcZYsxYUajbUqT5WpOJV6nTPyblibdLWgqF92YNDTqPTKE7I0Ylo4aBS0Lruiu6gukFpK3x0UUvgRMUh3KQIaYNEAAAAASUVORK5CYII=" width="12" height="20" /></span><span> respectively.  We obtain these values in MATLAB by generating a </span><span style=' font-style: italic;'>confusion matrix</span><span> using the </span><a href = "https://www.mathworks.com/help/stats/confusionmat.html"><span style=' font-family: monospace;'>confusionmat</span></a><span> function. The confusion matrix for a binary classifier is a 2x2 matrix whose elements are comprised of the three counts above, along with the true negative rate </span><span texencoding="t_n" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAoCAYAAADkDTpVAAACDklEQVRYR+3VS6hNURzH8c/1CnmnJBMGZCKvkseIkAET5FVEMjJQKI+JkSIRMvEuKY/SrTsTIlGkFEkxoKQ8BpL3m9btf7U79rn7nGuf2Vmj3d7//fuu9Vu/9V8tGjxaGqyvCSh0uGlR06JCBwoLak3RGrzDhULFioJaAKtxEstxtmzAMpwJ0eF4WRZgLDZjbQi+xzR8xpN6IHkWLUBbJyLd8atWSB6gHwZgJXaF0CLcwm+8qFU81XW2yacCkur6hj31aLfXVgN0w1v0x0XMq1s5fqgGGIf7UZM2e2/ZgPU4FKKTcbdsQEpRSlOK52D8LBPQE99C8DyWdlW82iZPx80QXYdjZQO2Y2eIjsYnHMH8HFAP/Ij36TlZmc7K35GXoiuYhedILeMqDuN4/LURU6N1HMUB7Edqio8xIXtmKgEp/x0b+jrOQkrQiszM0qrSIUyQmdiB60iNcUxM6lHHEvIAdzAps8mr8LXCniQwCNeihbfiBmagd7Y+z6JhmIhneJjj+0g8jfe7sTVayUdcwtyiPSgKTbrdTkRRL3zH7BDfhH3/CziHJViIZE0aqetuwfhMi2n/UMuVmZ1QiuKbSMmITETvYRSGYHH2aq0XMAW3cRAbgjww0pb8fxB963S1FBX5nzrrHszB5Sjug1fR2rdlLqkuWVRtAkPxBR8qC+q1qGiF/3xvAgota7hFfwDt614pcpJK/QAAAABJRU5ErkJggg==" width="12" height="20" /></span><span>, organized as follows:</span></div><div  class = 'S14'><span texencoding="C = \left(\begin{array}{cc} t_p &amp; f_n \\ f_p &amp; t_n\end{array}\right)" style="vertical-align:-17px"><img src="data:image/png;base64,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" width="86.5" height="45" /></span></div><div  class = 'S2'><span>In general, the confusion matrix for an </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">n</span><span>-class classifier is organized such that </span><span texencoding="C_{ij}" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACYAAAAoCAYAAACSN4jeAAADVElEQVRYR+3Ya8iecxwH8M8QUeYs1OYFm1MRkkNyWs3eeIPNMhRJjoVESEpCKUrMtGjFspryYsTYmmM5i5IzYZNTaWMms6xf/S79n+u57ue+7uvZ8zx78fzf3Hf3/3f4Xr/j97qn2E7PlO0Ul0lgg2ZmMmKTEcsI7IXDEJ9/4luszbs9cAA+HzRaId+lxo7FrTgd+zc4DWDvJuCfMGusgR2OuzA3Hf2Ch7Eav+JgXIKLCyD34+axBHYaXi0cPIWrMn11vzchAMUJkCE78GmTyjOwprB8JR4bwdNOeB9H4zh8ODCqFjUW9bGqMNw2AlXUdsXf2xrYbtllVYEvwaUtnZyaUT2qpfwwsZFSeQMeKDSi9X8ewFE82F8DyA8R7QVsd6xDfMZ5FFd3ddJFrxewsrPC7kl4u4uDrjq9gL2IswujO2NzVydd9HoBi1qqin4l5nQxPhqdJmBRVxsKo4txxWicdNFtAhar59PC2H25G7vYL3Wm4oiGWg0SEOvt91K4Cdi+ufsquYW4ZrSosBQX4gS8l/ZOxFt4BWf2Axb3/xVC26rG7sG1OBmfpP2D8BlWYEEbYGVXRpin4Z8WUQtHdyLGzR8N8rFH/639viO21GV7dWV04QuFcL/FHaKHZEpiaZ/f40GagO2QO3sIuF7A4vdY3mcluHj62VkPTYG7CFGLb+Dc2uK+JdN3PJbjxmQd12NGDu9hLGSkXRlj46VUrMAEMXwN3yB24TG52MPwg7gdm2rId8GTSTDPwXN5v192Yzz03vUU9+Nj4TxmWDDXam/WI/Z63pf0qC7zUfKzPbE+L6fjOzybUR6i0w9YJRy8KsI+E4dm/fyQJPCrPk1xIH5EPEAw4epcgGXZqY+0Lf4WDdhaZD6exm24t9AKMMFYohw+nghgj+MyxDB9pwAQr3URzXj1az0uWoejhWCkPN4x98nOfj4BRXqjS+c12WhbYy38N4oEmN/wMj7AF3gC5+GZfNNaNBHAoqs3puO7cUd+fwjX4cgaYfgf41hHLBwFrwuSWbKHr3NuBbNoPOMBrHIcc+v7HDdfNnRppznWtcYqvVPwZu7Q2BKX526NP2ImNGIxEoLexCqL9RP/fwybXSXC8UxlsIggoUGj+p7xBNYXTCmwFajVkinjHocNAAAAAElFTkSuQmCC" width="19" height="20" /></span><span> corresponds to the number of elements </span><span style=' font-style: italic;'>classified</span><span> as class </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">i</span><span> whose </span><span style=' font-style: italic;'>true class</span><span> is </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">j</span><span>. Better model performance is therefore indicated by higher counts on the diagonal vs. off-diagonal. The off-diagonal (incorrectly classified) elements of a confusion matrix indicate how predictive errors are distributed among the classes and error types.</span></div><div  class = 'S2'><span>    Use the control below to select a cuttoff value </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">ϵ</span><span> from a vector of 15 logarithmically-spaced values from </span><span texencoding="10^{-8}" style="vertical-align:-5px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAAmCAYAAACYsfiPAAADx0lEQVRoQ+3YaaiuUxQH8N9FkrGoa5Z5nmdJGVKGMkQ3QoakyDzzgYgMUcQHQyJThg+URELGUqaMmYdIkshQyNhf+9G+73163+c4zzmdc++76q23vdde+/9/1tprrb3nWMRkziLG15jwwu7xsYfHHp4dX2ATHI0N8TkexbP4fRD+whDSh+JBnIdHsDOux2M4DH/XpGc74eD/Ae9hx4rY5bgQW+Dt/0t4DZyIa/B9h0gPmN2xE1bDW3gKn3RY21VlJXyLN7FVtegY3I498MxECQfsOTi9LFwHn41AFCAJqR3wDZ7AgViuAMj/H7uyGqH3MdbFfmXPqN+FI7EUfutKeBWcWcjWa0YRXgFPY9uSPA7CH1iyANoTL2Jf/NQD6bNK1MVUHBPcGTugnOn5thh2hu/BO/gQD1SrRhGON/cu+muXrNksjyfikci9OKIHwuFwLc6obCWyXmmz3TVpvYEtO4R0dKIbuQ3Ht2ya8ePK+Jr4sgfS2+C1yk6O0f5tpLsSfg67dSCchJZwiqQu3tlCpkkomboYlxadJLR4potcgfwie+FJnIzn8VA50zkum+GL2mCfhJfAdyUxZY8N8FEL+ox/UMbjiZXL/9TRnL8ukoSYo7M0Pi2Zf5eycG7JFckhV+H8qSK81sB5XWyw6JeN85H/qkCs2LHMtX2I5gjdgFMrhSTGREwakSSv/6RPD6fevlQsJ5yWH+KqlKSUqMgCzUEXFxed1UsOyL6NhzPVjC+QR/oknNr6cAGS5mK9IcCb2hmVlKfHJ0ByUPUF7FoajzQgkdNw3UBt/neiT8In4Oay4csDrd4gyFdLnc74Ubh7EoRzJG7BIeXsLoutcXYZn890n4QDvMnKKRHbDSGR+r5pmT8Wd0yCcLM0jU3ay59LIvu1zWafhPepWruJhHTdEvbAe7iJPgmnDCRUIxNJWomEummYUtJ9El4VX1VoFx8oP81UytWflV4yar1u1hAO0DoZpct5twV9Xiea8TQgG00pwwHjfXo4pnNbubrskax9awuZOptfgCtnIuGm1gXbsNvS+uV2Fb37cHgLmfsxr4zn9pTWcNqkq4frRmFjvD8EYfrXc8t8Etnrle72SI2O3IhTpo1p2WgU4SSeXPFuqoBdhkvKpb4Nb9bkUe3g8vSSB4B4Md5Mb5v6mxtNvJyHgWmVYYQvKsTaAKXshET9jlTrLVM8mKtgJHU5hCNpMk7CL9PKtKOHJ4sp72Gbl2vf1+UFcdpKUBv4USE9WcIzbv2Y8IxzSc+Axh7u+YPOOHNjD884l/QM6B+TvMUnLtihDwAAAABJRU5ErkJggg==" width="30" height="19" /></span><span> to </span><span texencoding="10^{-2}" style="vertical-align:-5px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAAmCAYAAACYsfiPAAADjUlEQVRoQ+2YachMYRTHf6+1yBLKLmt2yppEUgpfkChJ1hRRIluJSFm/KB8IkZDlAyVZsmVLhKxlpyRRFIXs/XXm7XG7c+eZ251pXu89NTXzzDnnnv9zzvM/57llVDIpq2R4SQH/7xlPM5xmuGLswGBgNNAWuA8cBa6Ghf4/lPRCYH0IuEnAnuB6RQfcDbgCzAFOAPo9GxhrQGsC31zQ+QBuAcwCNgIfPCpdvocA/YFmwF3gDPDMw9ZXZZX52+UYVLc1xTsgWNo+gBWsymaeOW0DvMgRUUPgONAXeAucAkYBdYDz9v2jL6oIvYnAQeB7QEdr44AettHlf0cBbgLMN7Cuv1yA6wFngV7AMSOTH0AN24ShwGVgBPApAdBhLh4CTYH6wC/fkt5rjPfYdjFjlwuwsjnMlFsDL50HikWf2u99gDKUtDQC3gEbgEVxSeu2lYfsowCrhKQr2QHMCEGj9Wm23hJ4lTDiJVbOA4GvcQFfAAZ5nGER2gLTmwzsDgEzBdhp6ysAEY9EhKYz7yNrAH2Cog2/ZMfpSZgjH9KSnQ/gasB7IybZdADCHqr1RxaMCK2xfV8MiDd8RISoo+OKyPWiVdW5bE6SBNwqcF6rAL9DHqxnukTSwLPNRW2EuoKIcplNWRldJUEi0vwrSQJWv82Mc2LfuhERqiWpRUm6A/d80ppFR885DWwCRLSuiC+2AtcKAVh99og51nDRLgKEmFqMLVF70pQUR2pZ69OAczLgoCvwGejorieZ4Zm2m/J/HegXgeCGEYtUQmdeT/TbgekRunOBzYUCrMAzrHwT6B0RiG40Xez/qYA7GnpijaeWZIaH2ySlSPIp6ZGOXTwUeVglCVijpEpVkg9pqRJUEUWRJAFrdn3tRF01OMfaf2pXPx295gG7ggJPErACdclILPkgJPrOzroGkH9YtKBoE+7DitV9+yDW3hYCwGXzpcDaQoOMw9KaTzWMS6IuD+0B3a4k+4EJIWAOAONtXb34eSkCdgeFToDum9lknXMtE5HdchT7WI/Wkvqj+mRRJdcZFvHoirfFiWo1sNKdTwMRy+YQMAa4Yy8AlEVlU28T1X8PW5bLZ9xioY4CvNyAhcWitiMQPbMEWtsyqKugRH05M0pqyNCLti/FAhnnDMeNTVc2vUnUte+NXRLc1hXXb2y7XCUd23GpGqaASzUzScWVZjipnSxVP2mGSzUzScX1B3RQtCcq3c0CAAAAAElFTkSuQmCC" width="30" height="19" /></span><span>. The code will then compute and print the precision, recall, and </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> values for a given choice of </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">ϵ</span><span>. What value(s) produce the best results as judged by the fewest misclassified points? What about when judging by the precision, recall, and </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> score? The data and probability contours are also plotted for you to explore how the cuttoff value affects these values. </span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>epsilon = 1e</span></span><span>-4</span><span style="white-space: pre;"><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute the probability contours</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>Xvalprobs = mvnpdf(Xval,mu,sigma.^2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>yvalpred = Xvalprobs &lt; epsilon;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>confmat = confusionmat(yvalpred,dataval.Anomaly)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>precision = confmat(2,2)/(confmat(2,2)+confmat(1,2));</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>recall = confmat(2,2)/(confmat(2,2)+confmat(2,1)); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>F1 = 2*precision*recall/(precision+recall);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>fprintf(</span><span style="color: rgb(170, 4, 249);">'Epsilon: %g | Precision: %g | Recall: %g | F1: %g'</span><span>,epsilon, precision,recall,F1);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Probability contour plot</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>[Xplot,Yplot,Zplot] = probContour(dataval,mu,sigma); hold </span><span style="color: rgb(170, 4, 249);">on</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>contour(Xplot,Yplot,Zplot,[epsilon epsilon],</span><span style="color: rgb(170, 4, 249);">'r'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>errinds = yvalpred ~= yval;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(dataval.Throughput(errinds),dataval.Latency(errinds),</span><span style="color: rgb(170, 4, 249);">'mo'</span><span>,</span><span style="color: rgb(170, 4, 249);">'MarkerSize'</span><span>,10); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>hold </span><span style="color: rgb(170, 4, 249);">off</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>legend({</span><span style="color: rgb(170, 4, 249);">'Probability contours'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Normal behavior'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Anomalous behavior'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Cuttoff contour'</span><span>,</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>        </span><span style="color: rgb(170, 4, 249);">'Misclassified points'</span><span>},</span><span style="color: rgb(170, 4, 249);">'Location'</span><span>,</span><span style="color: rgb(170, 4, 249);">'northeast'</span><span>);  </span></span></div></div></div><div  class = 'S12'><span>If you searched through all of the </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">ϵ</span><span> values above, you found that the fewest number of misclassified points is 3, and the precision, recall, and </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> scores peak between </span><span texencoding="\epsilon = 10^{-4}" style="vertical-align:-5px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAG4AAAAmCAYAAAAlUK76AAAE7UlEQVR4Xu2aW6hWRRTHf0ZRFhEVaURFSQp2k5LuJFoilaKieamMirJ7DwlmD5FYCtlDilaUlxQpvKSVFEVGPUg3CrrQVaFCyqDoodQstTT+skaHae9vz/ft73xnb86sl3POnjUz/1n/mbXWrDm9SFJLC/SqJeoEmkRcTTdBIi4RV1ML1BR2OnGJuJpaoNqw7wFOBWaEMNOJqy5xFwEfAu8AVybiqkuUj+xo4DOgXyLuoFkOAcYBRwDPR/LYBxgNnAH8a8Z8H/grsn+zakuArcDDiTgQYTL+HOBMYClwW4RFpbPY9N4EDgeG2t8TgRcjxmhGZazFNLnHP3sycYrj1wCPAOd7Fowh7gbvVF4OvGv9hwNv2e8TgLXNMNNA9yTgU+AyYAuwuycTp517u50MnRAZWlJEnIjaaLrzgfsDgy8E7rVv5wBfliRPHuF1YA3wHHBYTyfOt+co4NVI4nSKxpuukoQfAmL07Tv79iRwX0nitAl0kuUqJYk4z6DDzPUUnTglI79Yv1+BvjmkSEe6kmOB3834LzVB4glAf+BtQCdX8yXiAgPGEqeLr06RZDlwSw4RK4Abre1Wc3HnNtAPh9kHTAcWAHcDmwOFAfa3vn8BXOvaYy/gp9klUD//AL4B9tg945kmdld3q8YS96zFReFV1eLxHOAPAHOtTTr/q3BELvg6YESgeygwBdgOrDNXrQRrvxQRdyTwFHAz8L0F+FOA662/7kFux0Vi7Fa1WOKUJFxtSO8AFuWgVpvbuEoqJrVxdS3HOKWmrwAXmLuYCvxjwJSlaVfOtDQ7Bq/iQe8YxQIdxYRdLY4TS9xXdtfTNJOB1TnzqW2ltX0MXNgirqxuLRF3nLlDBV5lYcp09nqjq+qgICq/HFt9kD9vh2juriZuG6Cyk0R3wDdygI8EXrO2nwB5o3aJXKXCkS79V4WD5rlK/44iMAIVikhTAfTbSKS6P8noZUQLWVVigNgT52eLjYgbY15JkBplnyUgZ3fNIm6QFTjVYx4wre2zdt+AscR9ZCFCSJU45G0W31V+Agzu1NKyiHvBSz4Exl0yHSYF4XaVeDq1TjdPLHGK7TpNkjstnmdh9ZOT9d7lucvXlUXcj8DJNrO7y/hAFIxVGa+jxBLnh4oHvZQ/XLPS/8fs49OA7n8dkZC444HfbOZ2H/06ZZV+0iE3KXeZJb536oqXgtxNEBJ3KfCeab9s71bt2kF1yiqVRLm3Nl2AjwFC/LKdihEu+zwK2NkuYxWNExI3EPjaOunZ/JKMAfQedRewzIAXzeHaq5BVXmE1QWEqeh1QqesmA3+WZxe3nrOtDBUzVqyNovVC4nRBlktzuyisisuV6iTusMp5V70ARy+gSUU/Cyyq+pwOfG62UMnpQJ3Q5nQJjE6kihSbmsRSSj0rOXkIeNRG1enTc8XfwBALvh9YmavVS3ApwCU667+ltOncY6ruXQoNYdbsT3ExoPVK9OziXsLlcfRGJ9GjZ8eTtSzi9KCnTElVa1+0s54AZnulrxJ27FjXEwGVo1ymHE6sGuwsQJX+LFHNUtm1vI9sIJFHUj8RuKFjK/EmalRklls8z3R/NqA6eT1RVH6SLUSeRI+qyrpd7bbjNil6Heg4oDRhnAUScXF2qpxWIq5ylMQBSsTF2alyWom4ylESBygRF2enymkl4ipHSRyg/wDhXvQnvsS/LQAAAABJRU5ErkJggg==" width="55" height="19" /></span><span> and </span><span texencoding="10^{-3}" style="vertical-align:-5px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAAmCAYAAACYsfiPAAADnElEQVRoQ+2YWahOURTHf9f0YCxDZhkzU8YHiUghhReRZEiKUiJjIVKGPEkiiYQMhTIrQ6IMIWOZKUkSQnkw9tf6arv3fOfsc+85p++636pb3z1nrb3Xf62113/tU0IVk5Iqhpci4P8948UMFzNcOSLQE5gGdAIeAoeB60Gu/w8lPQS4CDwGagOtDOhw4Hxp0JUdcE3gCjAXuAZ/WWcZsAbYA0ypCGBFbjawEfjoUenafCgwEGgB3APOAc89bH1VlEVl9Zhj0BZ4AZwAxpQHsJxdCMwz43bAywiPGgGngP7AO+AsMBaoZ+Wn3599UcXUG2aBnQHsjAO4GTDfwLp2UYAb2NnpY1EeB/wAalkQ5JDKcBTwJSaYKPXGwBngkvn+Ow7gvcAD4Alw0DGMAqxsjjB9ldcrx7Y98Mz+3wdMjkLg+b4uMBVYYk1LVTURuBAHsKt7B+jlUdLSka5kBzAzwGE9V7lJWgOvPUGFqbUERgMdgMWmqOppA3xyDX27tEpksAdgNbQFpqeI7w7wUnyZO1srgdWmo4amM+8jawH9BYkq8DjQDRgPHE0LcA3ggzUm7aEh4GmAR3ouzpSo9Jrab2VGfcNH1BB1dPKJaGqT0dXmtACrfNzzWg0o0zSMK385TjT0pDmfQOR0VI2qylQzLL69ajvq/NQP8VCUJIqSaCy8HweNh67mhS1AE+B9WhkWt+bOi4YLNZB8ok6tji0RPZ32ABGkIopbDohRdhn96chopFxq09Y/dkk2rVnANlv9BjAgBMRNQDwt0finMbA8omCdNEMF+RGgo6TGKUotI0kCluO5rnwL6BuCQM6oi0qmW3bKA1g2dWytr9Ykv4ctlCTgkTZJab84JS3+VNfNRJIErBJVqUriNC1VgioiE0kScHPgjeN1dcCln9wrnbGfjp6mJNcuVeBJApajbjPqbl8fSgPo6jzXANI5VYSlFk8asK6RG2wPde3tAWDcbi7qWFeIgC8Dg8yxsNtSR7tdSXU/MCkAzAFggj0XF+uynpn4ZtgdFLoY3+Vzcj2wyF6qkd12FPsB4miJZlzNvJlKFGA1Hl3xtjpe6XvRKptqgpyVzSGbY+8C+gCgLCqb+hQj/j1iWdaHgUwlDPAKAxbkkGhHIHrn8VbDgDKoq6BEvJwbJTUCzgG+ZYrUNovKcEV90vewHnbte2uXhMwoKMj5tAFXNGCJ2xcBJx7SAluwmOECS0ji7hQznHhIC2zBP81auSf80i3kAAAAAElFTkSuQmCC" width="30" height="19" /></span><span>. However, if you look closely there appears to be an optimal </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">ϵ</span><span> between these two values such that only two points will be misclassified. In the next section we discuss a method for finding this optimal value for a given performance metric.</span></div><h2  class = 'S11' id = 'H_E4CD52C0' ><span>Determine the optimal cuttoff value using performance curves</span></h2><div  class = 'S2'><span>The </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> statistic provides a good assessment of model performance in cases like the anomaly detection example, where the validation data is heavily skewed towards true negative examples which aren't included in the </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> computation- otherwise a model that classifies all values as negative would be judged as 'good'. A more general alternative to the </span><span texencoding="F_1" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAoCAYAAACb3CikAAACGElEQVRYR+3WTchNURTG8d+LAUmiDISB5COKIhkwIl9DFOWrTIkyEDJS3sJIiAmhmJAyIWKiJBMGijJQigwkQhgprdrqdDr3fNx71B2cNbl1z17r+ffstdfeI4YkRoaEQweS34nOkc6RqtNZ1SOXsLWqSI/ve3G9bm4VSNSZjFtYmyn6EHfxDeMwCfOwOv3G0lj/qE2QqHUah1LRH5iOnwUiAXUTmzANn9sGuY/1qWgIbSsR2InjmFMXItbV2ZoJ+JUpugdXS0R2YAN2tQ2yJrfXs/ChQmQs/rQNchKHU9HXWJQTiF54ixmI/ukr6mzNKyxM1QPqaEZpDC5jLlb1RZCSqkBm4n1G4CAeYyLmYws24gDO/U+Q3bhWQ2A23tVY13NJlSM3sD1lxxCLWTIeU7EYsVUvsGwQiKrjG8PpS5qasXYfLuQEo3/CsRh4A0WZIyvwLFN9Ad7k1L5jecH/eagp2J/GwNMi4jKQYziRkmJuxPzIRpyYaNIzJVbEPRVOHknOxui/0xTkCVampIuI27RpxIT9jdFUqzFIWBn98S96FqhJdjZtTWOQzbidEYlT8rWmaNGyvkHupUEVRV9iyQAQkdoXyDo8yAh/SvdL7bdFAXRjkDie8dIqikGcaQwy4A70TO9A8tZ0juQdeY6laaidbzri22jcGAVxX8XFGBFPySs4hY9Zgar3SBswtWp0IHmbOkeG1pG/yB1dKWWUkasAAAAASUVORK5CYII=" width="17" height="20" /></span><span> score is found by using </span><a href = "https://www.mathworks.com/help/stats/performance-curves.html"><span>performance curves</span></a><span> to select cutoff values. The idea behind performance curves is as follows: for a set of probability scores </span><span style="font-family: STIXGeneral, STIXGeneral-webfont, serif; font-style: italic; font-weight: 400; color: rgb(0, 0, 0);">S</span><span> obtained from a machine learning  model and a (sequential) set of probability cuttoff values </span><span texencoding="\epsilon_i" style="vertical-align:-6px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAoCAYAAAALz1FrAAAB9UlEQVRYR+3VS8iMcRTH8c8r5RIbZCFKFsrGJVEspBQLCyKUInIpt42wUgoLJZRLEUUuKRSFDcXKZUNsXBYopMhGCJF03v4zjccz7zPzmpnV899M0zn/8+33O+d/ni4dOF0dYCghTblc2lXa1ZQDTSWX09UWu0ZjFuL3E57iJ8bgaBGxqCcDcQQr8BIXMQpLU+GzWPY/kBG4gik4hTX4lQquxTHswM7eQoYkS4bjKubjd02x/viA9Qg1PZ56dh3CxnQz7HmbUyUAt/CsN5AJeJQuHsDmoiJF8Twl52oa+xAvMkUu4FKdwn0xFQ/wo5KTB3mDkSnhcE6x87hbB7Iax5P6cKH7ZCFD8THFQsXkIisy8bm4huU4Uw8yHXdS8DIWNAmJ9LCsMuq5SsbhSSp8H9NyIP2wDifT68+mFEIG4D0Gp5uxNl7VVAk7Q+EXLMS3FJuHxZiYVMSEVk9e47djV8oIVZvwHTOwAffSKqlOT7Io1B3EXmwrgvTBHmzN+PAZ+7E763nK25emag5uFEEq8bBmUvrzLi3IUFTvPMdYDMLXRiHNDFasnte4idnZi0WrvlFQrPvT2IKw7a/TKsgJrErTFZ+IUFR9K62CPMZ4LEK8+pXt6MltzMR1LGlX4+MzPSw1/58+tsquHgekhDT6frrzOmLXHwsgVinL6LPoAAAAAElFTkSuQmCC" width="12.5" height="20" /></span><span>, plot the values of the </span><span style=' font-style: italic;'>performance statistics</span><span>, </span><span texencoding="p_i^{1}" style="vertical-align:-8px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAsCAYAAAAATWqyAAAC9klEQVRYR+3XW6hVVRQG4O+EdCMLRXsoCiwQelHpIkYiQVSWkgSVoVZEGYgkGhH6Yj0UVBJRVA9d6GIk4YthKqR4gS5SFJUvRSgUUWRQVkRpkTJg7FhO176sfTwckT3hwFlzzTHGv/4xxj/mHnKCrKETBIcBkDITA0ZGi5FxuB/b8GFdg4x0as7BUqzEWNyMDaMBZDb+wmO4ajSBtD7+2UzNqDEyANJuYpxcqYm2m5R/F+NHrMNE3ISL8Cvew5dtKBk2I4vwQmpAK8Zq/ILnaoLei1dq9ocNpOXzNdyVDztxGVbgE9yOVZXgIWK/F2COG5C3cVs634/p+DafT8GBCmtXYvdIACkDzcQHRaAvMCX3bsSW4v2nuDRFrS6lPV2MpuLzdBwBIlC5fsK5uXk5InCs6/AorsjnP/AqnsAPVSe9DL3leDqNIj3rCxRn47fK3vjsonaaUrvfC5DNuCGtz8KfhadZ2JV723FNIwR5uBuQ03N6xvGNqRtlnCrQudg0EkCqX3sfXiqCzMBHufcWFvYDImy6MfIwHknnl+CrSqAx2IqrEUUYqvtzDZA4F+0eBXywHdBuQD7Oio9AIVSH01E4fx0LEkRIfQhd3Qq1DSYfqBT9Mec6AYl7Zkh5rBCx8/EvzsPjuCOV9RZ81yElc/Au7sTafhiJr3ynYvgZDiHqIoA9jyfxdw91EQzGR7RdnRh5BsvSMnIcHXQGvsc3+KcHAK0jwwKyN0d8WR+9xp+X82lashEK3ZiRCytD7c2sh14BVFlYgpi8a/BQP0AW48U0jP9fbooizz+V3XJ9XpwaMXIq9mByWl2bv9D6wfJ1+qkbDUf5K4s1ZkrcPeJ62FpRI+8j5Pu/BmguyLYO0Ysp3HGVQE5Lvagz2tfNWfE+dOYNPIhIUSMg3c43eR91dQ+ia0IEg5m2WtJN4psELs+2bm23ItT17n66ZjgAWrY7ciDGtWB+zT2mY7EeDwAtH2diQpc59H+8kUxNo48aACnpGjBSMnIEY72QLR+ubEkAAAAASUVORK5CYII=" width="17" height="22" /></span><span> and </span><span texencoding="p_{i}^2}" style="vertical-align:-8px"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACIAAAAsCAYAAAAATWqyAAADV0lEQVRYR+3Xaci1UxQG4OuTTBkiJFOhRAlliEhKZlEyf+YpfhBCSeGXzCKUKTMJP2TKTJkiMpQhUaaEMs9zt/Z52x7POc95zuc93/fjXfXW++y91973vtda915nnkXE5i0iOMwBaUZijpFpM7IcjsFm+APP4VZ8P00gq+ElrNk49AXshq/q8dnMkduwJM7HJ9gb5yIsnYaLpgFk+cLGJvi5OvBw3ICHscs0gKyBDfB4Iywb4zXchf2mAWSYYCc89+A4XL0wgVyCk7EWPl5YQFbEBzgSd09SvsnydcrfevgUd2AV7Il1Syk+gteHxCTVeTO+xglta7rK92BcVUpu4H8WvsQVLRsejetbxs/E1qWEf50EyMDnRhxWPp4qSplYR7AOwBnV5ivg2+r7WByI3fFjNR6N+WXw3cXIYN2dVbl9ji1LvDO/WKE8IYzl5lHPWECegh3xTQViI4TZmRIeB0jzoG3xbIPeaEM0Ihb5fgh74D68iY+q9ctiG+xTSvmfqXGARB1fLRvlgBzUtM+wahncHD/grbZcKGPflWTvFZqTcGnZIFRGFWuLnNe0r9R80EYAmpkah5EHsWvxCK25bW3b4eky8AR2GOfg5pouIEvhp+KUeEc3mlYDTV48MBtA6tumDK9tHLIVni9jt2P+JCDi08XI2TinbL4h3q4OWhyPYnsk+aK6X7QAybqU+8u1bvQNzYvYohwUofqrbJDNb8JBZS4hi9C1WdQ2TEZPBkn/n3WjGMkjFSmPRcTSY/yO1XEeDinKGj34cERIoqj341DcMmzdKCC55b2V4yvIO5G8CLArcUGjAxt2ThjMJYbaKCCX4cTimRingpYufcS7+K1HYi4QkPfKE59ErPNj3PP3Km/JpoWNKHRvRtauHrX8Dkk+9LWwcDwux4U4fRIg+VF0TXHM/9f1RVHWX1yqZWekcerFyBJ4A+sXrzzhj00I5J2yT9vT8K8tm8maNyW9x6C3yOLkyDPlWf+zB6A0yCnriN5OXX5NIOmaohdt9n7XZo355FX61FOREI20Lonv8h81n7w6CqmaiGCYGaolswlk0LXtW/rVI/om64KwUPs+WR7EtAX7t/QxI5P1/wKRfZbByh3v0Mx5sxmaXpeaA9Kka46RJiN/AzNSmi1+tztgAAAAAElFTkSuQmCC" width="17" height="22" /></span><span>. This plot called a performance curve and it provides a visual means to track the performance of a classifier as judged by the given metrics as the cutoff is varied. The most common performance statistics are the false positive rate and true positive rates. A performance curve generated using these two statistics is commonly known as a </span><a href = "https://en.wikipedia.org/wiki/Receiver_operating_characteristic"><span>Receiver Operating Characteristic</span></a><span> (ROC) curve. The point on the curve representing the ideal 'balance' between the two statistics (and thus the classifier best model) is referred to as the </span><span style=' font-style: italic;'>optimal operating point</span><span>- see the </span><a href = "https://www.mathworks.com/help/stats/perfcurve.html"><span style=' font-family: monospace;'>perfcurve</span></a><span> documentation for more on how this point is determined.</span></div><div  class = 'S2'><span>    Run the code below to compute the ROC curve and the optimal operating point for the current probability model using the </span><span style=' font-family: monospace;'>perfcurve</span><span> function, which returns the performance statistic values, the corresponding threshold values, and the cuttoff value corresponding to the optimal operating point. This value is determined with the assumption that the 'cost' for the two performance statistics (true and false positive rates for ROC curves) is equal, but that need not be the case in general. For example, false positives could be considered more 'costly' than false negatives in certain models and thus weights can be added to reflect this, or alternatively other performance statistics chosen by providing </span><span style=' font-family: monospace;'>perfcurve</span><span> with additional inputs- see the documentation for more details. </span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>[Xroc,Yroc,T,auc,Opt] = perfcurve(yval,Xvalprobs,0);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>Topt = T(Opt(1) == Xroc &amp; Opt(2) == Yroc);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>fprintf(</span><span style="color: rgb(170, 4, 249);">'Best epsilon found using ROC performance curve: %g'</span><span>,Topt)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Xroc,Yroc); hold </span><span style="color: rgb(170, 4, 249);">on</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Opt(1),Opt(2),</span><span style="color: rgb(170, 4, 249);">'ro'</span><span>); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>hold </span><span style="color: rgb(170, 4, 249);">off</span><span>; axis </span><span style="color: rgb(170, 4, 249);">square</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'False positive rate (1-specificity)'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'True positive rate (sensitivity)'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'ROC curve'</span><span>)</span></span></div></div></div><div  class = 'S12'><span style=' font-weight: bold;'>Implementation Note:</span><span> By default, a probability score greater than the cutoff corresponds to a 'positive' classification (i.e. y == 1), but in our anomaly detection model the opposite is true, therefore we added an additional input to </span><span style=' font-family: monospace;'>perfcurve</span><span> to associate the 'positive' class with those observations such that </span><span style=' font-family: monospace;'>yval(i)==0</span><span>.</span></div><h2  class = 'S11' id = 'H_B8C43CFF' ><span>Compare model performance using ROC curves</span></h2><div  class = 'S2'><span>In addition to helping evaluate potential cutoff values, ROC curves also offer a visual means for comparing the performance of two different classifier models. The main idea is that if one performance curve lies above another over a majority of the threshold values, the corresponding model is more robust. For a more quantitative comparison, the total area under the ROC curves is used to compare between models. As an example, recall that by calculating the variance of the two feature variables separately in our current model, we have implicitly assumed that these variables are independently distributed (corresponding to a diagonal covariance matrix). In the code below, we calculate the full covariance matrix for the multivariate normal distribution and use it as part of an alternative probability model. The ROC curves and areas under the curves are then used to compute the optimal cutoff values for each model and to compare their performance.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Replot existing ROC curve</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Xroc,Yroc,</span><span style="color: rgb(170, 4, 249);">'b'</span><span>); hold </span><span style="color: rgb(170, 4, 249);">on</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Opt(1),Opt(2),</span><span style="color: rgb(170, 4, 249);">'bo'</span><span>); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'False positive rate (1-specificity)'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'True positive rate (sensitivity)'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'ROC curve'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span style="color: rgb(2, 128, 9);">% Compute and plot the full covariance model ROC curve</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>Xvalprobs2 = mvnpdf(Xval,mu,cov(Xval));</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>[Xroc2,Yroc2,T2,auc2,Opt2] = perfcurve(yval,Xvalprobs2,0);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>Topt2 = T2(Opt2(1) == Xroc2 &amp; Opt2(2) == Yroc2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>fprintf(</span><span style="color: rgb(170, 4, 249);">'Best epsilon for full covariance model found: %g'</span><span>,Topt2)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Xroc2,Yroc2,</span><span style="color: rgb(170, 4, 249);">'r'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Opt2(1),Opt2(2),</span><span style="color: rgb(170, 4, 249);">'rx'</span><span>); hold </span><span style="color: rgb(170, 4, 249);">off</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>legend({</span><span style="color: rgb(170, 4, 249);">'Independent'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Optimal Point'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Full'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Optimal Point'</span><span>}, </span><span style="color: rgb(170, 4, 249);">'Location'</span><span>,</span><span style="color: rgb(170, 4, 249);">'NorthEast'</span><span>)</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>fprintf(</span><span style="color: rgb(170, 4, 249);">'Independent variable AUC: %g | Full covariance AUC: %g'</span><span>, auc,auc2);</span></span></div></div></div><div  class = 'S12'><span>From the plot above, we can see that the performance of the two models is generally comparable, and in fact both produce the same performance statistic values as the optimal operating point (though the corresponding threshold values are slightly different). The areas under the ROC curves are also comparable, which implies that their performance is generally equal and there is not much to be gained from including the full covariance matrix in our model.</span></div><h2  class = 'S11' id = 'H_76E52164' ><span>Fit a multivariate probability model to the high dimensional dataset</span></h2><div  class = 'S2'><span>In this section we use the tools from the previous sections to create an anomaly detection algorithm for the full dataset with 11 features. Run the code below to load the data. calculate the model parameters, and obtain the optimal cutoff value using the ROC curve. The model is then used to predict the number of outliers in the non-validation set- compare with your results from ex8.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span>clear;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>load(</span><span style="color: rgb(170, 4, 249);">'ex8data2.mat'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>mu = mean(Xval);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>sigma2 = cov(Xval);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>Xvalprobs = mvnpdf(Xval,mu,sigma2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>[Xroc,Yroc,T,auc,Opt] = perfcurve(yval,Xvalprobs,0);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>Topt = T(Opt(1) == Xroc &amp; Opt(2) == Yroc);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>fprintf(</span><span style="color: rgb(170, 4, 249);">'Best epsilon found using ROC: %e\n'</span><span>, Topt);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>confusionmat(Xvalprobs &lt; Topt,yval==1)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Xroc,Yroc); hold </span><span style="color: rgb(170, 4, 249);">on</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>plot(Opt(1),Opt(2),</span><span style="color: rgb(170, 4, 249);">'bx'</span><span>); hold </span><span style="color: rgb(170, 4, 249);">off</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>xlabel(</span><span style="color: rgb(170, 4, 249);">'False positive rate (1-specificity)'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>ylabel(</span><span style="color: rgb(170, 4, 249);">'True positive rate (sensitivity)'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>title(</span><span style="color: rgb(170, 4, 249);">'ROC curve'</span><span>); </span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span>fprintf(</span><span style="color: rgb(170, 4, 249);">'# of outliers predicted: %d'</span><span>,sum(mvnpdf(X,mu,sigma2) &lt; Topt));</span></span></div></div></div><h1  class = 'S0' id = 'T_F877B50F' ><span>Local Functions</span></h1><h2  class = 'S1' id = 'H_10E7FDFA' ><span style=' font-family: monospace;'>probContour</span></h2><div  class = 'S2' id = 'H_A0E9969C' ><span style=' font-family: monospace;'>propContour</span><span> plots the probability contours for a normal distribution and the Throughput-Latency validation dataset provided as a </span><span style=' font-family: monospace;'>table</span><span> input. The variable means and standard deviations are also provided as input to compute the normal PDF values from the fitted distribution for a grid of feature values.</span></div><div class="CodeBlock"><div class="inlineWrapper"><div  class = 'S8'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">function </span><span>[Xplot,Yplot,Zplot] = probContour(dataval,mu,sigma)</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Compute probability grid</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    [Xplot,Yplot] = meshgrid(linspace(min(dataval.Throughput),max(dataval.Throughput),200),</span><span style="color: rgb(14, 0, 255);">...</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>                             linspace(min(dataval.Latency),max(dataval.Latency)),200);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    Zplot = mvnpdf([Xplot(:),Yplot(:)],mu,diag(sigma).^2);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    Zplot = reshape(Zplot,size(Xplot));</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    </span><span style="color: rgb(2, 128, 9);">% Plot probability contours</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    figure; hold </span><span style="color: rgb(170, 4, 249);">on</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    contour(Xplot,Yplot,Zplot,10.^(-20:4:0),</span><span style="color: rgb(170, 4, 249);">'showtext'</span><span>,</span><span style="color: rgb(170, 4, 249);">'on'</span><span>,</span><span style="color: rgb(170, 4, 249);">'Color'</span><span>,</span><span style="color: rgb(170, 4, 249);">'k'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    plot(dataval.Throughput(~dataval.Anomaly),dataval.Latency(~dataval.Anomaly),</span><span style="color: rgb(170, 4, 249);">'bx'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    plot(dataval.Throughput(dataval.Anomaly),dataval.Latency(dataval.Anomaly),</span><span style="color: rgb(170, 4, 249);">'rx'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    title(</span><span style="color: rgb(170, 4, 249);">'Probability Density Contours'</span><span>);</span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    ylabel(</span><span style="color: rgb(170, 4, 249);">'Latency (ms)'</span><span>); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    xlabel(</span><span style="color: rgb(170, 4, 249);">'Throughput (mb/s)'</span><span>); </span></span></div></div><div class="inlineWrapper"><div  class = 'S9'><span style="white-space: pre;"><span>    hold </span><span style="color: rgb(170, 4, 249);">off</span><span>;</span></span></div></div><div class="inlineWrapper"><div  class = 'S10'><span style="white-space: pre;"><span style="color: rgb(14, 0, 255);">end</span></span></div></div></div></div>
<br>
<!-- 
##### SOURCE BEGIN #####
%% MATLAB Companion Script (1 of 2) for _Machine Learning_ ex8 (Optional)
%% Introduction
% Coursera's _Machine Learning_ was designed to provide you with a greater understanding 
% of machine learning algorithms- what they are, how they work, and where to apply 
% them. You are also shown techniques to improve their performance and to address 
% common issues. As is mentioned in the course, there are many tools available 
% that allow you to use machine learning algorithms _without_ having to implement 
% them yourself. This Live Script was created by MathWorks to help _Machine Learning_ 
% students explore the data analysis and machine learning tools available in MATLAB.
%% FAQ
% *Who is this intended for?*
%% 
% * This script is intended for students using MATLAB Online who have completed 
% ex8 and want to learn more about the corresponding machine learning tools in 
% MATLAB.
%% 
% *How do I use this script?*
%% 
% * In the sections that follow, read the information provided about the data 
% analysis and machine learning tools in MATLAB, then run the code in each section 
% and examine the results. You may also be presented with instructions for using 
% a MATLAB machine learning app. This script should be located in the ex8 folder 
% which should be set as your Current Folder in MATLAB Online.
%% 
% *Can I use the tools in this companion script to complete the programming 
% exercises?*
%% 
% * No. Most algorithm steps implemented in the programming exercises are handled 
% automatically by MATLAB machine learning functions. Additionally, the results 
% will be similar, but not identical, to those in the programming exercises due 
% to differences in implementation, parameter settings, and randomization.
%% 
% *Where can I obtain help with this script or report issues?*
%% 
% * As this script is not part of the original course materials, please direct 
% any questions, comments, or issues to the _MATLAB Help_ discussion forum.
%% Anomaly Detection
% In the first part of this Live Script, we will use tools from the <https://www.mathworks.com/products/statistics.html 
% Statistics and Machine Learning Toolbox> to implement an anomaly detection system. 
% We then discuss methods for fitting statistical distributions to measured data, 
% as well as adjusting and evaluating the performance of our detector. 
%% Files needed for this script
%% 
% * |ex8data1.mat| - First example dataset for anomaly detection
% * |ex8data2.mat| - Second example dataset for anomaly detection
%% Data Visualization and Probability Distribution Fitting
% In this section we visualize the sever data from ex8 using scatter plots and 
% histograms before fitting a distribution to the data using functions and apps 
% from the Statistics and Machine Learning Toolbox. 
%% Load the data
% Recall that the data used in the first part of ex8 consisted of two features: 
% measurements of the throughput (mb/s) and latency (ms) each server as well as 
% a separate set validation measurements and labels that denoted anomalous behavior. 
% Run the code in this section to load the variables |X|, |Xval| and |yval| into 
% the workspace and create a |table| for the validation data and labels, then 
% compute some summary statistics on the validation data. Recall that 0's denote 
% normal behavior and 1's denote anomalous behavior.

clear;
load('ex8data1.mat');
dataval = table(Xval(:,1),Xval(:,2),yval==1,'VariableNames',{'Throughput','Latency','Anomaly'});
summary(dataval)
%% Visualize the data using |scatterhist| 
% Before fitting a distribution to data, it's helpful to visualize the data 
% to see what existing probability distributions might make for a reasonable fit. 
% Run the code below to see how the values of the normal and anomalous data is 
% distributed across the two variable values using the <https://www.mathworks.com/help/stats/scatterhist.html 
% |scatterhist|> function.

scatterhist(dataval.Throughput,dataval.Latency,'Group',dataval.Anomaly,'Kernel','on','Marker','x')
xlabel('Throughput');
ylabel('Latency');
%% 
% From the resulting plot, the 'normal behavior' observations appears approximately 
% normally distributed with most observations concentrated symmetricaly about 
% the mean. The 'anomalous behavior' observations appear more evenly distributed 
% over the range of variable values and also appear symmetrically distributed 
% about the overall means, however there are considerably fewer anomalous observations.
%% Visualize distribution fits using |histfit|
% Below we provide code to visualize potential distribution fits using the <https://www.mathworks.com/help/stats/histfit.html 
% |histfit|> function, which plots a histogram of the data and the fitted distribution. 
% Run the code to plot two potential distribution fits for each variable, the 
% normal and t-distributions, for comparison.

f = figure;
subplot(2,2,1);
histfit(dataval.Throughput,25,'normal');
title('Normal distribution fit')
xlabel('Throughput');
axis square
subplot(2,2,2); 
histfit(dataval.Throughput,25,'tlocationscale');
title('t-distribution fit')
xlabel('Throughput');
subplot(2,2,3);
histfit(dataval.Latency,25,'normal');
title('Normal distribution fit')
xlabel('Latency');
axis square
subplot(2,2,4); 
histfit(dataval.Latency,25,'tlocationscale');
title('t-distribution fit')
xlabel('Latency');
set([f.Children.YLabel],'String','Count')
axis square
%% 
% While the t-distribution appears to offer better fit to the data based on 
% the above plots, the normal distribution is still a reasonable choice and offers 
% easier comparison with the results from ex8, so we will use that distribution 
% in the next few sections. 
%% Fit a probability distribution to data using |fitdist|
% To fit a distribution to each variable, we will use the <https://www.mathworks.com/help/stats/fitdist.html 
% |fitdist|> function, which takes a data vector and distribution name as input, 
% and returns the fitted distribution parameters as output. The number and meaning 
% of the parameters vary by distribution- see the <https://www.mathworks.com/help/stats/fitdist.html#btu538h-distname 
% documentation> for more details and available distributions. Run the code below 
% to fit a normal distribution to the Throughput data (we fit a normal distribution 
% to the Latency data in the next section). The |fitdist| function will return 
% a |NormalDistribution| variable that contains the parameters as well as additional 
% fit information including the confidence bounds for each parameter. We then 
% extract the parameters into the first elements of the variables |mu| and |sigma| 
% respectively. 

mu = zeros(1,2);
sigma = mu;
distMdl1 = fitdist(dataval.Throughput,'Normal')
mu(1) = distMdl1.mu;
sigma(1) = distMdl1.sigma;
%% 
% *Note:* If you have difficulty reading the instructions below while the app 
% is open in MATLAB Online, export this script to a pdf file which you can then 
% use to display the instructions in a separate browser tab or window. To export 
% this script, click on the 'Save' button in the 'Live Editor' tab above, then 
% select 'Export to PDF'.
%% Fit a probability distribution to data using the Distribution Fitter App
% In the next few sections we provide instructions for fitting a normal distribution 
% to the latency data using the<https://www.mathworks.com/help/stats/model-data-using-the-distribution-fitting-tool.html  
% Distribution Fitter App> and export/extract the model parameters:
%% 
% # In the '*Apps*' tab,  expand the list of apps and select '*Distribution 
% Fitter*' from the '*Math, Statistics, and Optimization*' group.
% # Click on the '*Data*' button.
% # Expand the '*Data*' drop-down menu under '*Import workspace vectors'* and 
% select '*Xval*'.
% # Click on the '*Select Column or Row*' button. In the box that appears, click 
% on the '*2*' at the top of the second column to select the entire column, then 
% click '*OK*'.
% # Click on the '*Create Data Set*' button, then click '*Close*'.
%% Fit a normal distribution and export the |NormalDistribution| variable to the workspace
%% 
% # In the Distribution Fitter window, click on the '*'New Fit*' button
% # In the '*New Fit*' window, confirm that the second column of |Xval| is selected 
% in '*Data*', and '*Normal*' is selected in *'Distribution*'.
% # Click the '*Apply*' button.
% # Click on the '*Save to Workspace*' button. 
% # In the '*Save fitted distribution as:*' box that appears, enter '*distMdl2*' 
% then click '*Ok*'
% # Close the '*Edit* *Fit*' menu (the 'New Fit' menu becomes the 'Edit Fit' 
% menu once a distribution is fitted).
%% Evaluate the fit and extract the parameters
%% 
% # In the plot shown, compare the fitted PDF with the histogram. 
% # The default plot view is 'Density Plot'. To further examine the fit, select 
% one of the additional plot views in the '*Display Type*' drop-down menu.
% # When you are finished, close the Distribution Fitter App (there is no need 
% to save the current session).
% # Run the code below to extract the values of $\mu$ and $\sigma$ from the 
% exported distribution variable into the second elements of the |mu| and |sigma| 
% vectors created earlier.

mu(2) = distMdl2.mu;
sigma(2) = distMdl2.sigma;
%% Obtain the multivariate normal PDF values using |mvnpdf| 
% Now that we have fitted the probability distribution model coefficients, we'll 
% create a contour plot of the probability distribution as in ex8. Run the code 
% below to plot the observations and probability contours using the local function 
% |probContour| defined at the end of this script. This function uses the <https://www.mathworks.com/help/stats/mvnpdf.html 
% |mvnpdf|> function and the normal distribution parameters fitted previously 
% to calculate the multivariate probability values for a grid of throughput and 
% latency values.

probContour(dataval,mu,sigma);
%% Model Assessment and Cutoff Parameter Selection
% After obtaining the distribution parameters, the next step in implementing 
% the anomaly detection model is to select a cutoff parameter for flagging anomalies 
% using the labeled validation data. In this section we use tools including the 
% confusion matrix and performance curves for visualizing and evaluating model 
% performance for various choices of this parameter, then we provide a method 
% for obtaining this value automatically using the |perfcurve| function.
%% Obtain the confusion matrix and calculate the $F_1$ score
% In ex8 you used the validation set to select a probability cutoff parameter 
% $\epsilon$ for anomaly prediction corresponding to the best $F_1$ score. Recall 
% that the $F_1$ score depends on the _precision_ and _recall_ values, which in 
% turn depend on the true positive, false positive, and false negative counts 
% denoted $t_p$, $f_p$, and $f_n$ respectively.  We obtain these values in MATLAB 
% by generating a _confusion matrix_ using the <https://www.mathworks.com/help/stats/confusionmat.html 
% |confusionmat|> function. The confusion matrix for a binary classifier is a 
% 2x2 matrix whose elements are comprised of the three counts above, along with 
% the true negative rate $t_n$, organized as follows:
% 
% $$C = \left(\begin{array}{cc} t_p & f_n \\ f_p & t_n\end{array}\right)$$
% 
% In general, the confusion matrix for an $n$-class classifier is organized 
% such that $C_{ij}$ corresponds to the number of elements _classified_ as class 
% $i$ whose _true class_ is $j$. Better model performance is therefore indicated 
% by higher counts on the diagonal vs. off-diagonal. The off-diagonal (incorrectly 
% classified) elements of a confusion matrix indicate how predictive errors are 
% distributed among the classes and error types.
% 
% Use the control below to select a cuttoff value $\epsilon$ from a vector of 
% 15 logarithmically-spaced values from $10^{-8}$ to $10^{-2}$. The code will 
% then compute and print the precision, recall, and $F_1$ values for a given choice 
% of $\epsilon$. What value(s) produce the best results as judged by the fewest 
% misclassified points? What about when judging by the precision, recall, and 
% $F_1$ score? The data and probability contours are also plotted for you to explore 
% how the cuttoff value affects these values. 

epsilon = 1e-4;
% Compute the probability contours
Xvalprobs = mvnpdf(Xval,mu,sigma.^2);
yvalpred = Xvalprobs < epsilon;
confmat = confusionmat(yvalpred,dataval.Anomaly)
precision = confmat(2,2)/(confmat(2,2)+confmat(1,2));
recall = confmat(2,2)/(confmat(2,2)+confmat(2,1)); 
F1 = 2*precision*recall/(precision+recall);
fprintf('Epsilon: %g | Precision: %g | Recall: %g | F1: %g',epsilon, precision,recall,F1);
% Probability contour plot
[Xplot,Yplot,Zplot] = probContour(dataval,mu,sigma); hold on;
contour(Xplot,Yplot,Zplot,[epsilon epsilon],'r');
errinds = yvalpred ~= yval;
plot(dataval.Throughput(errinds),dataval.Latency(errinds),'mo','MarkerSize',10); 
hold off;
legend({'Probability contours','Normal behavior','Anomalous behavior','Cuttoff contour',...
        'Misclassified points'},'Location','northeast');  
%% 
% If you searched through all of the $\epsilon$ values above, you found that 
% the fewest number of misclassified points is 3, and the precision, recall, and 
% $F_1$ scores peak between $\epsilon = 10^{-4}$ and $10^{-3}$. However, if you 
% look closely there appears to be an optimal $\epsilon$ between these two values 
% such that only two points will be misclassified. In the next section we discuss 
% a method for finding this optimal value for a given performance metric.
%% Determine the optimal cuttoff value using performance curves
% The $F_1$ statistic provides a good assessment of model performance in cases 
% like the anomaly detection example, where the validation data is heavily skewed 
% towards true negative examples which aren't included in the $F_1$ computation- 
% otherwise a model that classifies all values as negative would be judged as 
% 'good'. A more general alternative to the $F_1$ score is found by using <https://www.mathworks.com/help/stats/performance-curves.html 
% performance curves> to select cutoff values. The idea behind performance curves 
% is as follows: for a set of probability scores $S$ obtained from a machine learning  
% model and a (sequential) set of probability cuttoff values $\epsilon_i$, plot 
% the values of the _performance statistics_, $p_i^{1}$ and $p_{i}^2}$. This plot 
% called a performance curve and it provides a visual means to track the performance 
% of a classifier as judged by the given metrics as the cutoff is varied. The 
% most common performance statistics are the false positive rate and true positive 
% rates. A performance curve generated using these two statistics is commonly 
% known as a <https://en.wikipedia.org/wiki/Receiver_operating_characteristic 
% Receiver Operating Characteristic> (ROC) curve. The point on the curve representing 
% the ideal 'balance' between the two statistics (and thus the classifier best 
% model) is referred to as the _optimal operating point_- see the <https://www.mathworks.com/help/stats/perfcurve.html 
% |perfcurve|> documentation for more on how this point is determined.
% 
% Run the code below to compute the ROC curve and the optimal operating point 
% for the current probability model using the |perfcurve| function, which returns 
% the performance statistic values, the corresponding threshold values, and the 
% cuttoff value corresponding to the optimal operating point. This value is determined 
% with the assumption that the 'cost' for the two performance statistics (true 
% and false positive rates for ROC curves) is equal, but that need not be the 
% case in general. For example, false positives could be considered more 'costly' 
% than false negatives in certain models and thus weights can be added to reflect 
% this, or alternatively other performance statistics chosen by providing |perfcurve| 
% with additional inputs- see the documentation for more details. 

[Xroc,Yroc,T,auc,Opt] = perfcurve(yval,Xvalprobs,0);
Topt = T(Opt(1) == Xroc & Opt(2) == Yroc);
fprintf('Best epsilon found using ROC performance curve: %g',Topt)
plot(Xroc,Yroc); hold on;
plot(Opt(1),Opt(2),'ro'); 
hold off; axis square;
xlabel('False positive rate (1-specificity)');
ylabel('True positive rate (sensitivity)');
title('ROC curve')
%% 
% *Implementation Note:* By default, a probability score greater than the cutoff 
% corresponds to a 'positive' classification (i.e. y == 1), but in our anomaly 
% detection model the opposite is true, therefore we added an additional input 
% to |perfcurve| to associate the 'positive' class with those observations such 
% that |yval(i)==0|.
%% Compare model performance using ROC curves
% In addition to helping evaluate potential cutoff values, ROC curves also offer 
% a visual means for comparing the performance of two different classifier models. 
% The main idea is that if one performance curve lies above another over a majority 
% of the threshold values, the corresponding model is more robust. For a more 
% quantitative comparison, the total area under the ROC curves is used to compare 
% between models. As an example, recall that by calculating the variance of the 
% two feature variables separately in our current model, we have implicitly assumed 
% that these variables are independently distributed (corresponding to a diagonal 
% covariance matrix). In the code below, we calculate the full covariance matrix 
% for the multivariate normal distribution and use it as part of an alternative 
% probability model. The ROC curves and areas under the curves are then used to 
% compute the optimal cutoff values for each model and to compare their performance.

% Replot existing ROC curve
plot(Xroc,Yroc,'b'); hold on;
plot(Opt(1),Opt(2),'bo'); 
xlabel('False positive rate (1-specificity)');
ylabel('True positive rate (sensitivity)');
title('ROC curve');

% Compute and plot the full covariance model ROC curve
Xvalprobs2 = mvnpdf(Xval,mu,cov(Xval));
[Xroc2,Yroc2,T2,auc2,Opt2] = perfcurve(yval,Xvalprobs2,0);
Topt2 = T2(Opt2(1) == Xroc2 & Opt2(2) == Yroc2);
fprintf('Best epsilon for full covariance model found: %g',Topt2)
plot(Xroc2,Yroc2,'r');
plot(Opt2(1),Opt2(2),'rx'); hold off;
legend({'Independent','Optimal Point','Full','Optimal Point'}, 'Location','NorthEast')
fprintf('Independent variable AUC: %g | Full covariance AUC: %g', auc,auc2);
%% 
% From the plot above, we can see that the performance of the two models is 
% generally comparable, and in fact both produce the same performance statistic 
% values as the optimal operating point (though the corresponding threshold values 
% are slightly different). The areas under the ROC curves are also comparable, 
% which implies that their performance is generally equal and there is not much 
% to be gained from including the full covariance matrix in our model.
%% Fit a multivariate probability model to the high dimensional dataset
% In this section we use the tools from the previous sections to create an anomaly 
% detection algorithm for the full dataset with 11 features. Run the code below 
% to load the data. calculate the model parameters, and obtain the optimal cutoff 
% value using the ROC curve. The model is then used to predict the number of outliers 
% in the non-validation set- compare with your results from ex8.

clear;
load('ex8data2.mat');
mu = mean(Xval);
sigma2 = cov(Xval);
Xvalprobs = mvnpdf(Xval,mu,sigma2);
[Xroc,Yroc,T,auc,Opt] = perfcurve(yval,Xvalprobs,0);
Topt = T(Opt(1) == Xroc & Opt(2) == Yroc);
fprintf('Best epsilon found using ROC: %e\n', Topt);
confusionmat(Xvalprobs < Topt,yval==1)
plot(Xroc,Yroc); hold on;
plot(Opt(1),Opt(2),'bx'); hold off;
xlabel('False positive rate (1-specificity)');
ylabel('True positive rate (sensitivity)');
title('ROC curve'); 
fprintf('# of outliers predicted: %d',sum(mvnpdf(X,mu,sigma2) < Topt));
%% Local Functions
%% |probContour|
% |propContour| plots the probability contours for a normal distribution and 
% the Throughput-Latency validation dataset provided as a |table| input. The variable 
% means and standard deviations are also provided as input to compute the normal 
% PDF values from the fitted distribution for a grid of feature values.

function [Xplot,Yplot,Zplot] = probContour(dataval,mu,sigma)
    % Compute probability grid
    [Xplot,Yplot] = meshgrid(linspace(min(dataval.Throughput),max(dataval.Throughput),200),...
                             linspace(min(dataval.Latency),max(dataval.Latency)),200);
    Zplot = mvnpdf([Xplot(:),Yplot(:)],mu,diag(sigma).^2);
    Zplot = reshape(Zplot,size(Xplot));
    % Plot probability contours
    figure; hold on;
    contour(Xplot,Yplot,Zplot,10.^(-20:4:0),'showtext','on','Color','k');
    plot(dataval.Throughput(~dataval.Anomaly),dataval.Latency(~dataval.Anomaly),'bx');
    plot(dataval.Throughput(dataval.Anomaly),dataval.Latency(dataval.Anomaly),'rx');
    title('Probability Density Contours');
    ylabel('Latency (ms)'); 
    xlabel('Throughput (mb/s)'); 
    hold off;
end
##### SOURCE END #####
--></body></html>